{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4265f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f4f4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed_room', 'dining_room', 'living_room']\n",
      "Types of rooms found:  3\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir('room_dataset')\n",
    "room_types = os.listdir('room_dataset')\n",
    "\n",
    "print(room_types)\n",
    "print(\"Types of rooms found: \", len(room_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cba7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bed_room', 'room_dataset/bed_room/bed-1303451__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bed-1846251__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bed-3786264__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bed-4065946__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bed-4343379__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bed-4343382__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bed-4540208__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bedroom-3102376__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bedroom-374982__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bedroom-4072391__340 (1).jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bedroom-460762__340.jpg')\n",
      "('bed_room', 'room_dataset/bed_room/bedroom-690129__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/apartment-185778__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/apartment-185779__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/apartment-2094648__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/architectural-224242__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/architecture-3214528__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/cafeteria-544871__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/candles-126159__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/centerpiece-714019__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/chair-3306118__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/chair-3321246__340.jpg')\n",
      "('dining_room', 'room_dataset/dining_room/dining-2112653__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/couch-1835923__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/dining-room-332207__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/furniture-998265__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/house-2563735__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/interior-2685521__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/kitchen-2165756__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/kitchen-3690727__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/kitchen-living-room-4043091__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-living-room-1644496__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-1048191__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-1523480__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-2037945__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-2155376__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-2569325__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-2732939__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-3164434__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-670240__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-690174__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/living-room-728732__340.jpg')\n",
      "('living_room', 'room_dataset/living_room/pexels-photo-245208.jpeg')\n",
      "('living_room', 'room_dataset/living_room/pexels-photo-275484.jpeg')\n",
      "('living_room', 'room_dataset/living_room/pexels-photo-276583.jpeg')\n",
      "('living_room', 'room_dataset/living_room/pexels-photo-276724.jpeg')\n",
      "('living_room', 'room_dataset/living_room/pexels-photo-279719.jpeg')\n"
     ]
    }
   ],
   "source": [
    "rooms = []\n",
    "\n",
    "for item in room_types:\n",
    "    all_rooms = os.listdir('room_dataset' + '/' + item)\n",
    "\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item, str('room_dataset' + '/' + item) + '/' + room))\n",
    "        print(rooms[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01a79d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  room type                                       image\n",
      "0  bed_room  room_dataset/bed_room/bed-1303451__340.jpg\n",
      "1  bed_room  room_dataset/bed_room/bed-1846251__340.jpg\n",
      "2  bed_room  room_dataset/bed_room/bed-3786264__340.jpg\n",
      "3  bed_room  room_dataset/bed_room/bed-4065946__340.jpg\n",
      "4  bed_room  room_dataset/bed_room/bed-4343379__340.jpg\n"
     ]
    }
   ],
   "source": [
    "rooms_df = pd.DataFrame(data=rooms, columns=['room type', 'image'])\n",
    "print(rooms_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c7217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rooms in dataset:  47\n",
      "rooms in each categpry: \n",
      "room type\n",
      "living_room    24\n",
      "bed_room       12\n",
      "dining_room    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of rooms in dataset: \", len(rooms_df))\n",
    "\n",
    "room_count = rooms_df['room type'].value_counts()\n",
    "\n",
    "print(\"rooms in each categpry: \")\n",
    "print(room_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e100e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"bool\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m filenames \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[1;32m---> 14\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m)\n\u001b[0;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (im_size, im_size))\n\u001b[0;32m     16\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"bool\") to str"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "path = 'room_dataset/'\n",
    "\n",
    "im_size = 244\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in room_types:\n",
    "    data_path = path + str(i)\n",
    "    filenames = [i in os.listdir(data_path)]\n",
    "\n",
    "    for file in filenames:\n",
    "        img = cv2.imread(data_path + '/' + file)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a63f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "\n",
    "images = images / 255.0\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e49ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "y = rooms_df['room type'].vales\n",
    "\n",
    "y_labelencoder = LabelEncoder()\n",
    "y = y_labelencoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc86889",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "Y = onehotencoder.fit_transform(y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45625f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, Y, test_size = 0.1, random_state=42)\n",
    "\n",
    "print(X_train.shaep, X_test.shape)\n",
    "print(y_train.shaep, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ec7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras import layers \n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model \n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ffab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x, f, filters):\n",
    "    F1, F2, F3 = filters #64, 64, 256\n",
    "    x_shortcut = x \n",
    "\n",
    "    # First layer \n",
    "    x = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1, 1), padding = 'valid')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Second layer\n",
    "    x = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Third layer\n",
    "    x = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "\n",
    "    # Final step: Add shortcut value to F(x), and pass it through a RELU activation\n",
    "    x = Add([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convalutional_block(x, f, filters, s=2):\n",
    "    F1, F2, F3 = filters #64, 64, 256\n",
    "    x_shortcut = x \n",
    "\n",
    "    # First layer \n",
    "    x = Conv2D(filters = F1, kernel_size = (1, 1), strides = (s, s))(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Second layer\n",
    "    x = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Third layer\n",
    "    x = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "    ### Shorcut Path\n",
    "    x_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s, s), padding = 'valid')(x_shortcut)\n",
    "    x_shortcut = BatchNormalization(axis = 3)(x_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to F(x), and pass it through a RELU activation\n",
    "    x = Add([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b72e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(224, 224, 3), classes=3):\n",
    "    \"\"\" \n",
    "    Implementation of the ResNet-50 architecture:\n",
    "    Conv2D -> Batch Norm -> Relu -> Max Pool -> Conv Block -> ID Block*2 -> Conv Block -> ID Block*3\n",
    "    -> Conv Block -> ID Block*5 -> Conv Block -> ID Block*2 -> Avg Pool -> Top Player\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input with the shape input_shape\n",
    "    x_input = Input(input_shape)\n",
    "\n",
    "    # Zero-padding \n",
    "    x = ZeroPadding2D((3, 3))(x_input) # 3,3 padding\n",
    "\n",
    "    # Stage 1\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), stride=(2, 2))(x)\n",
    "\n",
    "    # Stage 2\n",
    "    x = convalutional_block(x, f=3, filters=[64, 64, 256], s=1)\n",
    "\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "\n",
    "    # stage 3\n",
    "    x = convalutional_block(x, f=3, filters=[128, 128, 512], s=2)\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    \n",
    "    # stage 4\n",
    "    x = convalutional_block(x, f=3, filters=[256, 256, 1024], s=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "\n",
    "    # stage 5\n",
    "    x = convalutional_block(x, f=3, filters=[512, 512, 2048], s=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048]) \n",
    "    x = identity_block(x, 3, [512, 512, 2048]) \n",
    "\n",
    "    # Avg Pool\n",
    "    x = AveragePooling2D((2, 2), name='avg_pool')(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax', name='fc' + str(classes), keras_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    # Create model \n",
    "    model = Model(inputs = x_input, outputs = x, name='ResNet50')\n",
    "\n",
    "    return model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (224, 224, 3), classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='catagorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5658b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate((X_test, y_test))\n",
    "print(\"Loss: \", str(preds[0]))\n",
    "print(\"Task Accuracy: \", str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread \n",
    "\n",
    "img_path = 'test_img.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print(\"Input image shape: \", x.shape)\n",
    "my_image = imread(img_path)\n",
    "imshow(my_image)\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fc8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3b683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
