{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9c664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed_room', 'dining_room', 'living_room']\n",
      "Types of room found:  3 \n",
      "\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-1303451__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-1846251__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-3786264__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-4065946__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-4343379__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-4343382__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bed-4540208__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bedroom-3102376__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bedroom-374982__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bedroom-4072391__340 (1).jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bedroom-460762__340.jpg')\n",
      "('bed_room', 'data/room_dataset/bed_room/bedroom-690129__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/apartment-185778__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/apartment-185779__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/apartment-2094648__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/architectural-224242__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/architecture-3214528__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/cafeteria-544871__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/candles-126159__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/centerpiece-714019__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/chair-3306118__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/chair-3321246__340.jpg')\n",
      "('dining_room', 'data/room_dataset/dining_room/dining-2112653__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/couch-1835923__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/dining-room-332207__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/furniture-998265__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/house-2563735__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/interior-2685521__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/kitchen-2165756__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/kitchen-3690727__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/kitchen-living-room-4043091__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-living-room-1644496__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-1048191__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-1523480__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-2037945__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-2155376__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-2569325__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-2732939__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-3164434__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-670240__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-690174__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/living-room-728732__340.jpg')\n",
      "('living_room', 'data/room_dataset/living_room/pexels-photo-245208.jpeg')\n",
      "('living_room', 'data/room_dataset/living_room/pexels-photo-275484.jpeg')\n",
      "('living_room', 'data/room_dataset/living_room/pexels-photo-276583.jpeg')\n",
      "('living_room', 'data/room_dataset/living_room/pexels-photo-276724.jpeg')\n",
      "('living_room', 'data/room_dataset/living_room/pexels-photo-279719.jpeg')\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir('data/room_dataset')\n",
    "room_types = os.listdir('data/room_dataset')\n",
    "\n",
    "print(room_types)\n",
    "print(\"Types of room found: \", len(room_types), \"\\n\")\n",
    "\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in room_types:                #bed_room/dining_room/living_room\n",
    "    all_rooms = os.listdir('data/room_dataset/' + item)\n",
    "\n",
    "    for room in all_rooms:\n",
    "                # room type,                                     image path\n",
    "        rooms.append((item, str('data/room_dataset/' + item) + '/' + room))\n",
    "        print(rooms[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5c72ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  room_type                                       image_path\n",
      "0  bed_room  data/room_dataset/bed_room/bed-1303451__340.jpg\n",
      "1  bed_room  data/room_dataset/bed_room/bed-1846251__340.jpg\n",
      "2  bed_room  data/room_dataset/bed_room/bed-3786264__340.jpg\n",
      "3  bed_room  data/room_dataset/bed_room/bed-4065946__340.jpg\n",
      "4  bed_room  data/room_dataset/bed_room/bed-4343379__340.jpg\n"
     ]
    }
   ],
   "source": [
    "rooms_df = pd.DataFrame(rooms, columns=['room_type', 'image_path'])\n",
    "print(rooms_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019ea7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rooms:  47\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of rooms: \", len(rooms_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db17dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rooms in each catagory: \n",
      "room_type\n",
      "living_room    24\n",
      "bed_room       12\n",
      "dining_room    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "room_count = rooms_df['room_type'].value_counts()\n",
    "print(\"Rooms in each catagory: \")\n",
    "print(room_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360617d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "path = 'data/room_dataset'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for room in room_types:\n",
    "    data_path = path + '/' + room\n",
    "\n",
    "    file_names = [file for file in os.listdir(data_path)]\n",
    "\n",
    "    for file in file_names:\n",
    "        img_path = data_path + '/' + file\n",
    "        img = cv2.imread(img_path) # Read the image as array\n",
    "        img = cv2.resize(img, (60, 60)) # Resize the image to 60x60 pixels\n",
    "        images.append(img)\n",
    "        labels.append(room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a05f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 60, 60, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the image list to numpy array\n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6848883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 60, 60, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = images / 255.0  # Normalize the images to [0, 1] range\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed_room' 'bed_room' 'bed_room' 'bed_room' 'bed_room']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "y = rooms_df['room_type'].values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahs_snohmej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_label_encoder = LabelEncoder()\n",
    "y = y_label_encoder.fit_transform(y)  # Encode the labels to integers\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)  # Reshape to 2D array for OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "Y = onehot_encoder.fit_transform(y) # One-hot encode the labels\n",
    "print(Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (42, 60, 60, 3) (42, 3)\n",
      "Testing data shape:  (5, 60, 60, 3) (5, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs:  10800\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "num_classes = Y.shape[1]  # Number of unique room types\n",
    "\n",
    "n_inputs = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]  # Flatten the input images\n",
    "print(\"Number of inputs: \", n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6b5a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture hyperparameters\n",
    "learing_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b32891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = X_train.shape[1]\n",
    "n_channels = X_train.shape[3]  # Number of channels in the images (3 for RGB)\n",
    "# x = tf.placeholder(tf.float32, [None, img_size, img_size, n_channels])\n",
    "\n",
    "# y_ = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "# print(\"Shape of placeholder\", x.shape, y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ce55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME') # y = wx + b\n",
    "    x = tf.nn.bias_add(x, b) # Add bias(b)\n",
    "    return tf.nn.relu(x) # Apply ReLU activation function\n",
    "\n",
    "def maxpool2d(x, k=2):      # windwow size = k(2)       strides = k(2)\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb1c4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {               # 5X5 filter size, 32 filters for first layer, 64 for second layer, etc.\n",
    "    'w1': tf.Variable(tf.random.truncated_normal([5, 5, n_channels, 32]), name='w1'),\n",
    "                        # Here in 2nd layer, 32 means 32 filtered images generated, 64 for next layer, etc.\n",
    "    'w2': tf.Variable(tf.random.truncated_normal([5, 5, 32, 64]), name='w2'),\n",
    "    'w3': tf.Variable(tf.random.truncated_normal([5, 5, 64, 128]), name='w3'), \n",
    "    'wd1': tf.Variable(tf.random.truncated_normal([8 * 8 * 128, 2048]), name='wd1'), # Flattened size after conv layers\n",
    "    # 2048 is the number of neurons in the fully connected layer\n",
    "    'wout': tf.Variable(tf.random.truncated_normal([2048, num_classes]), name='wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.truncated_normal([32]), name='b1'),\n",
    "    # Here, 32 means bias for 32 filters in the first layer, 64 for second layer, etc.\n",
    "    'b2': tf.Variable(tf.random.truncated_normal([64]), name='b2'),\n",
    "    'b3': tf.Variable(tf.random.truncated_normal([128]), name='b3'),\n",
    "    'bd1': tf.Variable(tf.random.truncated_normal([2048]), name='bd1'),\n",
    "    'bout': tf.Variable(tf.random.truncated_normal([num_classes]), name='bout')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = {\n",
    "#     'conv1': tf.Variable(tf.random.truncated_normal([5, 5, n_channels, 32], stddev=0.1), name='conv1'),\n",
    "#     'conv2': tf.Variable(tf.random.truncated_normal([5, 5, 32, 64], stddev=0.1), name='conv2'),\n",
    "#     'conv3': tf.Variable(tf.random.truncated_normal([5, 5, 64, 128], stddev=0.1), name='conv3'),\n",
    "#     'fc1': tf.Variable(tf.random.truncated_normal([8 * 8 * 128, 2048], stddev=0.1), name='fc1'),\n",
    "#     'out': tf.Variable(tf.random.truncated_normal([2048, num_classes], stddev=0.1), name='out')\n",
    "# }       \n",
    "\n",
    "# biases = {\n",
    "#     'conv1': tf.Variable(tf.random.truncated_normal([32], stddev=0.1), name='conv1'),\n",
    "#     'conv2': tf.Variable(tf.random.truncated_normal([64], stddev=0.1), name='conv2'),\n",
    "#     'conv3': tf.Variable(tf.random.truncated_normal([128], stddev=0.1), name='conv3'),     \n",
    "#     'fc1': tf.Variable(tf.random.truncated_normal([2048], stddev=0.1), name='fc1'),\n",
    "#     'out': tf.Variable(tf.random.truncated_normal([num_classes], stddev=0.1), name='out')\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):\n",
    "    # Reshape input to 4D tensor: [batch_size, height, width, channels]\n",
    "    x = tf.reshape(x, shape=[-1, img_size, img_size, n_channels])\n",
    "\n",
    "    print(\"Shape of input tensor: \", x.shape) #60x60x3\n",
    "\n",
    "    # Convolutional & Pooling Layer 1\n",
    "    conv1 = conv2d(x, weights['w1'], biases['b1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    print(\"Shape after conv1: \", conv1.shape) #30x30x32\n",
    "\n",
    "\n",
    "    # Convolutional & Pooling Layer 2\n",
    "    conv2 = conv2d(conv1, weights['w2'], biases['b2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    print(\"Shape after conv2: \", conv2.shape) #15x15x64\n",
    "    \n",
    "\n",
    "    # Convolutional & Pooling Layer 3\n",
    "    conv3 = conv2d(conv2, weights['w3'], biases['b3'])\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "    print(\"Shape after conv3: \", conv3.shape) #8x8x128\n",
    "\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    # Reshape conv3 output to fit fully connected layer input 8x8x128 = 8192\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]]) # Flatten the output\n",
    "    print(\"Shape after flattening: \", fc1.shape) #8192\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print(\"Shape after fc1: \", fc1.shape) #2048\n",
    "\n",
    "    # Output Layer\n",
    "    out = tf.add(tf.matmul(fc1, weights['wout']), biases['bout'])\n",
    "    print(\"Shape of output layer: \", out.shape) #num_classes\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b29b1480",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the model \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m conv_net(\u001b[43mx\u001b[49m, weights, biases)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the model \n",
    "model = conv_net(x, weights, biases)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfddb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learing_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "# init = tf.global_variables_initializer() \n",
    "## No need to initialize variables in TensorFlow 2.x, as it uses eager execution by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history = []\n",
    "epochs = 10\n",
    "\n",
    "# the execution \n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "y_train = y_train.todense()  # Convert sparse matrix to dense format\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    a, c = sess.run([optimizer, loss], feed_dict={x: X_train, y_: y_train})\n",
    "    cost_history.append(c)\n",
    "    print(f'Epoch {epoch + 1}, Loss: {c:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "y_test = y_test.todense()  # Convert sparse matrix to dense format\n",
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y_, 1))\n",
    "print(correct_prediction)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy)\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = sess.run(accuracy, feed_dict={x: X_test, y_: y_test})\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
